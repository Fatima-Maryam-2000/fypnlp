{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description\n",
      "Our project named Humanitarian Aid Distribution, will introduce transparency into the process of collecting funds/donations and distributing aid and supplies through the use of blockchain. Anyone can view who allocated which funds for what purposes.  The features are as follows.  The user should be able to donate funds. The user should be able to donate to a specific cause. The user should be able to view how much they have contributed overall. The user should be able to view the funding for each cause. The admin user should be able to view donated funds. The admin user should be able to allocate funds to a cause. Once the goal amount has been reached for a cause, it should be closed for donations. If there is a time limit for donation/cause, then it will no longer receive funds if limit has expired. User will call on payable function of contract. There will be a function to transfer money from one contract to another (for allocating funds).\n",
      "GoNotes will generate precise notes from video samples. In GoNotes, we extract the audio from video samples, and then transcribe the text from the given audio samples. The text is refined and the lecture will be highlighted to depict the important points and the key terms. The problem that was discovered was that video lectures tend to be quite lengthy and it becomes nearly impossible to revise them without proper lecture notes. So, we used both audio features and textual features to locate emphasized parts of the lectures. This way, by generating precise lecture notes, students will have access to well prepared lecture notes without putting too much effort and saving a lot of time.\n",
      "RAR is an AI/computer vision based system that will provide assistance to the driver as road awareness is added in the rover using deep learning algorithms implemented on Raspberry Pi. The system consists of two stages. The first stage focuses on “Traffic sign board detection” and the second stage focuses on “Traffic sign classification and recognition”. Video input from the raspberry pi camera module will be taken from the surroundings and whenever a sign appears, the system will generate alerts to notify the driver through an Android application.\n"
     ]
    }
   ],
   "source": [
    "f = open('data.json',encoding=\"utf8\")\n",
    "data = json.load(f)\n",
    "for i in data['ideas']:\n",
    "    print(i['Description'])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
